### Video Gen 

> Generating videos for different courses quickly with the help of AI.

### Original Inspiration  

Near the end of July, we were tasked with generating a bunch of videos for the upcoming BI cohort from August to November. So I wanted to make the most of it to put together videos to ensure the content was relevant and engaging similar to the lectures. Over the course of the video generation, I attempted a few different approaches to generate videos quickly as it was an ambitious goal to generate a bunch of content in a short amount of time.  

## Approaches

The following were a few approaches I had taken to generate the videos and finally land on the best approach for myself. Please note, YMMV and how you feel the approach works for you. Here they are:

1. [Transcribe, Edit and Regenerate Audio (Unchanged)](#1-transcribe-edit-and-regenerate-audio-unchanged)
2. [Transcribe, Edit with AI and Regenerate Audio](#2-transcribe-edit-with-ai-and-regenerate-audio)
3. [Dictate, Edit Text and Generate Audio - Final Approach, Most Useful](#3-dictate-edit-text-and-generate-audio)

Below i'll outline a bit of how each of the steps kind of worked and the corresponding files that helped me in the process.  

### 1. Transcribe, Edit and Regenerate Audio (Unchanged)

To begin, I first downloaded the videos from vimeo and specifically used a library from github called [Private Vimeo Downloader](https://github.com/Tusko/vimeo-private-downloader) to download the videos. There's an option to parse the videos from their audio file which I had enabled and would then get the videos in a separate `mov/` and `m4a/` folder.  

#### A. Parse Audio 

script: `1_parse_audio.py`  

Once the downloads were complete, I noticed `openai` can only permit 4 minute increments of transcribing at a time. So, I first parsed the audio files from the `parts/` folder and then used a python script to partition the audio files into 4 minute increments and export them into a `parts/audio_partitions/` folder.  

Then I used a python script to transcribe the audio files from the `parts/audio_partitions/` folder. This created a series of audio files that were approximately 3 - 4 minutes in length.

#### B. Transcribe

script: `2_transcribe.py` (Dormant script, do not use)

Before having access to the transcripts generated by vimeo, I then used the OpenAI api to be able to transcribe the different chunks of audio and then save the transcripts into text files for each of the corresponding partitions of audio and then stored them in the `parts/transcripts/` folder.

However, this approach was sort of futile because I would then need to go through each of the files and edit the text file by file. 

Some early issues with this:  
- The transcripts were not always in a consistent format and sometimes had some random characters in the middle of the text.
- Occasionally the text output was empty because there was no audio so openAI had no idea what to say.
- The separate files made it easy to get lost when trying to edit the text files.

#### C. Edit and Regenerate Audio (Test) 

script: `3_generate_audio.py` (Dormant script, do not use)

After having the text files, I then used the python script to edit the text files. This involved a few things:  
- Removing the random characters that were in the middle of the text.
- Removing the empty text files.

But as it would take a long time, I never really proceeded with this approach, especially without a clear naming convention and not being able to be certain the audio would be of quality


#### D. Other Issues  

The following are a few other issues with this approach:
- Because the videos were lectures, at times there were irrelevant topics that were not entirely relevant in the video.
- The transcription would sometimes write one thing that could be incorrect such as names or "said" acronyms. 


### 2. Transcribe, Edit with AI and Regenerate Audio

Now that I had the transcripts and ran into some challenges with editing and updating it, I thought about using the OpenAI Assistants API to possibly adjust the transcripts and then use it to generate the audio via API as well. The idea was simple, create an assistant that would traverse each bit of text at the current step and the next step to be able to update the text at each step relevant to the lecture material. $40 in API credits later and the attempt was still pretty... bad. This is the process and my findings as well.

#### A. Transcribe (but also collate)

script: `3_preprocess_transcripts.py`

I took the same text files and made the most of their existence by using a python script to collate them into excel to be a bit more manageable. So the script would process the subfolders and then create a csv file with the following columns:
- Folder Name
- Partition
- Transcript

This saved a CSV file that I could then use to edit the transcripts, but I quickly made a few additions to be able to add some features and context to then be able to pass it to open AI.

#### B. Manual Edits in Excel  

At this point, I would take the excel CSVs generated, and decided to make a single master sheet that contained all of the courses I was assigned.

I added a few columns to be able to update programmatically and see if there was any way I could make the most out of the previous content. Here are the columns and their description:

- Module + Class - A description of the module at the time and the class to provide context for the assistant
- Class Description - Description of what that lecture would be
- Original Text - The text from the partition being referenced
- Previous Text - Simply a reference to the previous partition's text to determine if there was something in there that could provide context
- Processed - A flag to indicate if the AI has processed the batch of text
- Length Original - The length of the original text
- New Text - The new text generated by the AI
- Thread ID - The ID of the thread created by the AI - kept most of the same class in a single thread to avoid hallucination
- Timestamp - Timestamp of the received message from the AI
- Final Script - Basically an update of the script from the AI by me
- Length Final Script - Count of the characters - Audio API only accepts 4096 characters
- Ready for Audio - A flag to indicate if the audio can be generated
- Final Audio - Path to the audio file

#### C. Update Transcripts

script: `4_update_transcripts.py`  

In between the manual steps of editing, I made a master excel that would record all of the new text where I set up an assistant to regenerate the transcript to be focused on the Module + Class and the Class Description to be the topics. I passed the original text and previous text also to the assistant as part of the user prompt and would update each transcript line by line.

The script would go class by class and ensure it only processed the class where text was available and changed the "Processed" flag to "Yes".

#### D. Regenerate Audio

script: `5_generate_audio.py`

This script was then used to generate the audio for the classes using OpenAI and my updates to the final script.

#### E. Other Issues

The following are a few other issues with this approach:
- The transcripts generated were not the best quality since they would include "10 minute breaks" and random sidebars in the class like looking at jobs.
- I played with temperature to avoid hallucination but it didn't really help.
- I played with top_p to avoid hallucination but it didn't really help.
- I realized I was spending more time adjusting the assistant than was worthwhile


### 3. Dictate, Edit Text and Generate Audio

This was my final attempt to make the most of the audio generated by the OpenAI API and my understanding of the classes since I reviewed them anyways. Instead of having the AI generate the speech, I would record my speech as dictation to finally generate the audio.

#### A. Dictate

This was a process of me recording my speech when I would cover a topic or record a video. I originally would read the transcript that I had from the original class, but it was still sometimes off topic. So I tested a few different ways until I finally decided on creating the teaching plan, understanding what I was going to talk about and then dictating what I wanted to say.

#### B. Edit Text

I would go line by line ensuring that the text recorded from my dictation was accurate and on topic as well as correct language. So, I would revise what I would dictate each time and ensure that the result was cohesive and made sense.

#### C. Generate Audio

I finally would batch out the transcript into 4096 character chunks and place it into the excel file. Then I would use the python script to generate the audio. This was a quick process and I was able to get the audio generated in a few minutes. As I would edit the video with the audio file, I would listen to the audio and correct any errors I had in the single audio file over and over until I could move onto the next audio file.

### Final Thoughts

The final approach through dictation and editing was probably the most efficient approach and made the most of the AI and my understanding of the classes. I would use the AI sparingly and only on generating the audio for the videos instead of the actual script.

### Considerations 

The following are a few things that I would like to consider in the future:
- Improve dictation with another method of recording (ie quality microphone or different dictation from the defaults on MacOS) 
- Improve the dictation script using the assistant instead of the original transcript from the lectures  
